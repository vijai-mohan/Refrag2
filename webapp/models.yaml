# Global model configurations. Each key is a model identifier (can be HF repo id).
# Models not listed here will use defaults.
# You can optionally supply `eos_token_id` (single int) or `stop_token_ids` (list of ints)
# for models that require an explicit token id to stop generation. Example usage:
# models:
#   my-org/my-model:
#     eos_token_id: 50256
#   some/other-model:
#     stop_token_ids: [220, 220]

defaults:
  stop_markers: ["<|fim_suffix|>", "<end_of_turn>", "<|endoftext|>"]
  streaming: true
  use_tokenizer_template: true
  add_generation_prompt: true
  # Regex used to remove short assistant-intro greetings at the start of generation.
  # This is conservative and intended to strip autogenerated polite openings like
  # "Hello! How can I assist you today?". It's configurable per-model and can be disabled by setting it to null.
  intro_strip_regex: '^(?:\s*(?:hello|hi|hey)[!.]?\s*|\s*how can i (?:assist|help)[^\n]*[\n]?|\s*how may i help you[^\n]*[\n]?|\s*how can i help you today[^\n]*[\n]?)[\s\n]*'
  # Common system prompt applied to all models (can be overridden per-model)
  system_prompt: |
    You are a helpful, honest, and knowledgeable AI assistant.
    You answer questions, explain concepts, and provide reasoning clearly and accurately.
    When uncertain, say so rather than guessing.
    Always be concise and avoid unnecessary repetition.
    When asked to perform multi-step reasoning or coding, explain your approach briefly before producing the final answer.
    If the user provides context (e.g., retrieved documents), ground your answers in that context faithfully and cite or reference it naturally.

models:
  # Example per-model overrides. Replace the eos_token_id/stop_token_ids with values you discover locally
  # using the tokenizer (see instructions in the README or below).
  ibm-granite/granite-4.0-350M:
    stop_markers: ["<|fim_suffix|>"]
    streaming: true
    use_tokenizer_template: true
    # eos_token_id: 50256  # uncomment and set to the correct EOS id for this model if needed
  google/gemma-3-1b-it:
    stop_markers: ["<end_of_turn>"]
    streaming: true
    use_tokenizer_template: true
    # stop_token_ids: [1]  # example: single token id that should signal stop
  default:
    stop_markers: ["<end_of_turn>", ""]
    streaming: true
    use_tokenizer_template: true
