{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c4a8d2",
   "metadata": {},
   "source": [
    "# Refrag Evaluation Results\n",
    "\n",
    "Load evaluation summaries under the current run's `eval/` folder and display them in a paper-style table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c8eaf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "EVAL_ROOT = Path('eval')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b994f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_runs(eval_root: Path) -> list[dict]:\n",
    "    \"\"\"Collect per-run summaries (single runs or suites).\"\"\"\n",
    "    runs: list[dict] = []\n",
    "\n",
    "    def _append_run(run: dict, source: Path) -> None:\n",
    "        metrics = run.get('metrics', {}) if isinstance(run, dict) else {}\n",
    "        runs.append(\n",
    "            {\n",
    "                'name': run.get('baseline') or run.get('run_name') or run.get('model'),\n",
    "                'model': run.get('model'),\n",
    "                'accuracy_avg': metrics.get('accuracy_avg'),\n",
    "                'perplexity_avg': metrics.get('perplexity_avg'),\n",
    "                'lm_eval': run.get('lm_eval', {}),\n",
    "                'ragas': run.get('ragas', {}),\n",
    "                'source': str(source),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    for summary_path in eval_root.rglob('summary.json'):\n",
    "        data = json.loads(summary_path.read_text())\n",
    "        if isinstance(data, dict) and 'runs' in data:\n",
    "            for run in data['runs']:\n",
    "                _append_run(run, summary_path.parent)\n",
    "        elif isinstance(data, dict):\n",
    "            _append_run(data, summary_path.parent)\n",
    "\n",
    "    return runs\n",
    "\n",
    "def build_metric_rows(runs: list[dict]) -> list[dict]:\n",
    "    \"\"\"Flatten lm-eval metrics across runs and tasks.\"\"\"\n",
    "    rows: list[dict] = []\n",
    "    for run in runs:\n",
    "        tasks = run.get('lm_eval', {}).get('tasks', {}) or {}\n",
    "        for task_name, metrics in tasks.items():\n",
    "            if not isinstance(metrics, dict):\n",
    "                continue\n",
    "            for metric_name, value in metrics.items():\n",
    "                rows.append(\n",
    "                    {\n",
    "                        'name': run.get('name'),\n",
    "                        'model': run.get('model'),\n",
    "                        'task': task_name,\n",
    "                        'metric': metric_name,\n",
    "                        'value': value,\n",
    "                        'source': run.get('source'),\n",
    "                    }\n",
    "                )\n",
    "    return rows\n",
    "\n",
    "def format_mmlu_table(runs: list[dict]) -> pd.DataFrame:\n",
    "    \"\"\"Create a paper-style table for MMLU acc_norm ± stderr by model.\"\"\"\n",
    "    rows = []\n",
    "    for run in runs:\n",
    "        mmlu = (run.get('lm_eval', {}) or {}).get('tasks', {}).get('mmlu', {}) or {}\n",
    "        acc_norm = mmlu.get('acc_norm,none') or mmlu.get('acc_norm') or mmlu.get('acc_norm,all')\n",
    "        stderr = mmlu.get('acc_norm_stderr,none') or mmlu.get('acc_norm_stderr') or mmlu.get('acc_norm_stderr,all')\n",
    "        if acc_norm is None:\n",
    "            continue\n",
    "        display_name = run.get('name') or run.get('model')\n",
    "        cell = f\"{acc_norm:.3f}\" if stderr is None else f\"{acc_norm:.3f} ± {stderr:.3f}\"\n",
    "        rows.append({'Model': display_name, 'MMLU acc_norm ± stderr': cell})\n",
    "    return pd.DataFrame(rows).set_index('Model') if rows else pd.DataFrame(columns=['MMLU acc_norm ± stderr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e743bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 run entries from /home/vijai/code/Refrag/eval\n"
     ]
    }
   ],
   "source": [
    "runs = load_runs(EVAL_ROOT)\n",
    "print(f\"Loaded {len(runs)} run entries from {EVAL_ROOT.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e5d17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_avg</th>\n",
       "      <th>perplexity_avg</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLaMA2-7B-Full-Context</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>0.256509</td>\n",
       "      <td>None</td>\n",
       "      <td>eval/refrag_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama2-7B_full_context</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>0.256509</td>\n",
       "      <td>None</td>\n",
       "      <td>eval/refrag_paper/llama2-7B_full_context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ibm-granite-granite-4.0-350M</td>\n",
       "      <td>ibm-granite/granite-4.0-350M</td>\n",
       "      <td>0.248076</td>\n",
       "      <td>None</td>\n",
       "      <td>eval/ibm-granite-granite-4.0-350M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Granite-4.0-350M-FC</td>\n",
       "      <td>ibm-granite/granite-4.0-350M</td>\n",
       "      <td>0.196407</td>\n",
       "      <td>None</td>\n",
       "      <td>eval/refrag_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ibm-granite-granite-4.0-350M</td>\n",
       "      <td>ibm-granite/granite-4.0-350M</td>\n",
       "      <td>0.196407</td>\n",
       "      <td>None</td>\n",
       "      <td>eval/refrag_paper/ibm-granite-granite-4.0-350M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name                          model  accuracy_avg  \\\n",
       "0        LLaMA2-7B-Full-Context  meta-llama/Llama-2-7b-chat-hf      0.256509   \n",
       "1        llama2-7B_full_context  meta-llama/Llama-2-7b-chat-hf      0.256509   \n",
       "2  ibm-granite-granite-4.0-350M   ibm-granite/granite-4.0-350M      0.248076   \n",
       "3           Granite-4.0-350M-FC   ibm-granite/granite-4.0-350M      0.196407   \n",
       "4  ibm-granite-granite-4.0-350M   ibm-granite/granite-4.0-350M      0.196407   \n",
       "\n",
       "  perplexity_avg                                          source  \n",
       "0           None                               eval/refrag_paper  \n",
       "1           None        eval/refrag_paper/llama2-7B_full_context  \n",
       "2           None               eval/ibm-granite-granite-4.0-350M  \n",
       "3           None                               eval/refrag_paper  \n",
       "4           None  eval/refrag_paper/ibm-granite-granite-4.0-350M  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if runs:\n",
    "    run_df = pd.DataFrame(runs)\n",
    "    cols = ['name', 'model', 'accuracy_avg', 'perplexity_avg', 'source']\n",
    "    display(run_df[cols].sort_values(by=['accuracy_avg', 'perplexity_avg'], ascending=[False, True]).reset_index(drop=True))\n",
    "else:\n",
    "    print('No summaries found under eval/. Run evaluation first.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0b49cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Granite-4.0-350M-FC</th>\n",
       "      <th>LLaMA2-7B-Full-Context</th>\n",
       "      <th>ibm-granite-granite-4.0-350M</th>\n",
       "      <th>llama2-7B_full_context</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ibm-granite/granite-4.0-350M</th>\n",
       "      <th>meta-llama/Llama-2-7b-chat-hf</th>\n",
       "      <th>ibm-granite/granite-4.0-350M</th>\n",
       "      <th>meta-llama/Llama-2-7b-chat-hf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">hellaswag</th>\n",
       "      <th>acc,none</th>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.353050</td>\n",
       "      <td>0.577600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_norm,none</th>\n",
       "      <td>0.518300</td>\n",
       "      <td>0.755300</td>\n",
       "      <td>0.409150</td>\n",
       "      <td>0.755300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_norm_stderr,none</th>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.078875</td>\n",
       "      <td>0.004299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_stderr,none</th>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.078832</td>\n",
       "      <td>0.004940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mathqa</th>\n",
       "      <th>acc,none</th>\n",
       "      <td>0.346399</td>\n",
       "      <td>0.287772</td>\n",
       "      <td>0.223199</td>\n",
       "      <td>0.287772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">piqa</th>\n",
       "      <th>acc_norm,none</th>\n",
       "      <td>0.693689</td>\n",
       "      <td>0.772035</td>\n",
       "      <td>0.746844</td>\n",
       "      <td>0.772035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_norm_stderr,none</th>\n",
       "      <td>0.010755</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.072044</td>\n",
       "      <td>0.009788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_stderr,none</th>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.009909</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.009909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">winogrande</th>\n",
       "      <th>acc,none</th>\n",
       "      <td>0.565114</td>\n",
       "      <td>0.664562</td>\n",
       "      <td>0.682557</td>\n",
       "      <td>0.664562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_stderr,none</th>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.073633</td>\n",
       "      <td>0.013270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                     Granite-4.0-350M-FC  \\\n",
       "model                           ibm-granite/granite-4.0-350M   \n",
       "task       metric                                              \n",
       "hellaswag  acc,none                                 0.406100   \n",
       "           acc_norm,none                            0.518300   \n",
       "           acc_norm_stderr,none                     0.004997   \n",
       "           acc_stderr,none                          0.004911   \n",
       "mathqa     acc,none                                 0.346399   \n",
       "...                                                      ...   \n",
       "piqa       acc_norm,none                            0.693689   \n",
       "           acc_norm_stderr,none                     0.010755   \n",
       "           acc_stderr,none                          0.010883   \n",
       "winogrande acc,none                                 0.565114   \n",
       "           acc_stderr,none                          0.013933   \n",
       "\n",
       "name                                   LLaMA2-7B-Full-Context  \\\n",
       "model                           meta-llama/Llama-2-7b-chat-hf   \n",
       "task       metric                                               \n",
       "hellaswag  acc,none                                  0.577600   \n",
       "           acc_norm,none                             0.755300   \n",
       "           acc_norm_stderr,none                      0.004299   \n",
       "           acc_stderr,none                           0.004940   \n",
       "mathqa     acc,none                                  0.287772   \n",
       "...                                                       ...   \n",
       "piqa       acc_norm,none                             0.772035   \n",
       "           acc_norm_stderr,none                      0.009788   \n",
       "           acc_stderr,none                           0.009909   \n",
       "winogrande acc,none                                  0.664562   \n",
       "           acc_stderr,none                           0.013270   \n",
       "\n",
       "name                            ibm-granite-granite-4.0-350M  \\\n",
       "model                           ibm-granite/granite-4.0-350M   \n",
       "task       metric                                              \n",
       "hellaswag  acc,none                                 0.353050   \n",
       "           acc_norm,none                            0.409150   \n",
       "           acc_norm_stderr,none                     0.078875   \n",
       "           acc_stderr,none                          0.078832   \n",
       "mathqa     acc,none                                 0.223199   \n",
       "...                                                      ...   \n",
       "piqa       acc_norm,none                            0.746844   \n",
       "           acc_norm_stderr,none                     0.072044   \n",
       "           acc_stderr,none                          0.081818   \n",
       "winogrande acc,none                                 0.682557   \n",
       "           acc_stderr,none                          0.073633   \n",
       "\n",
       "name                                   llama2-7B_full_context  \n",
       "model                           meta-llama/Llama-2-7b-chat-hf  \n",
       "task       metric                                              \n",
       "hellaswag  acc,none                                  0.577600  \n",
       "           acc_norm,none                             0.755300  \n",
       "           acc_norm_stderr,none                      0.004299  \n",
       "           acc_stderr,none                           0.004940  \n",
       "mathqa     acc,none                                  0.287772  \n",
       "...                                                       ...  \n",
       "piqa       acc_norm,none                             0.772035  \n",
       "           acc_norm_stderr,none                      0.009788  \n",
       "           acc_stderr,none                           0.009909  \n",
       "winogrande acc,none                                  0.664562  \n",
       "           acc_stderr,none                           0.013270  \n",
       "\n",
       "[138 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_rows = build_metric_rows(runs) if runs else []\n",
    "if metric_rows:\n",
    "    metric_df = pd.DataFrame(metric_rows)\n",
    "    pivot = metric_df.pivot_table(index=['name', 'model'], columns=['task', 'metric'], values='value')\n",
    "    display(pivot.T)\n",
    "else:\n",
    "    print('No per-task metrics available.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "if runs:\n",
    "    mmlu_df = format_mmlu_table(runs)\n",
    "    if not mmlu_df.empty:\n",
    "        display(mmlu_df)\n",
    "    else:\n",
    "        print('No MMLU metrics found in the loaded runs.')\n",
    "else:\n",
    "    print('No runs loaded to build MMLU table.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
